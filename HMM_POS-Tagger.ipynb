{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and validation set in the ratio 80:20\n",
    "\n",
    "train_set,test_set = train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80310\n",
      "20366\n"
     ]
    }
   ],
   "source": [
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'NUM', 'CONJ', 'ADV', 'ADJ', 'PRT', 'VERB', '.', 'X', 'PRON', 'DET', 'NOUN', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "#check how many unique tags are present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_given_tag(word,tag,train_bag= train_tagged_words):\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist)    \n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0]==word]    \n",
    "    word_count_given_tag = len(w_in_tag)    \n",
    "    \n",
    "    return (word_count_given_tag,tag_count)\n",
    "\n",
    "#emission probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transitionprobability\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    \n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    \n",
    "    count_of_t1 = len(t1_tags)\n",
    "    \n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    \n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    \n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4424, 6957)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN','DET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUM</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>ADV</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>VERB</th>\n",
       "      <th>.</th>\n",
       "      <th>X</th>\n",
       "      <th>PRON</th>\n",
       "      <th>DET</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.184220</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.035345</td>\n",
       "      <td>0.026062</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.119243</td>\n",
       "      <td>0.202428</td>\n",
       "      <td>0.001428</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.351660</td>\n",
       "      <td>0.037487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.040615</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>0.113611</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.150384</td>\n",
       "      <td>0.035126</td>\n",
       "      <td>0.009330</td>\n",
       "      <td>0.060373</td>\n",
       "      <td>0.123491</td>\n",
       "      <td>0.349067</td>\n",
       "      <td>0.055982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.029868</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.081458</td>\n",
       "      <td>0.130721</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>0.339022</td>\n",
       "      <td>0.139255</td>\n",
       "      <td>0.022886</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.071373</td>\n",
       "      <td>0.032196</td>\n",
       "      <td>0.119472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.021748</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.063301</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.696893</td>\n",
       "      <td>0.080583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.082975</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>0.401174</td>\n",
       "      <td>0.045010</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>0.250489</td>\n",
       "      <td>0.019569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.083886</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.030663</td>\n",
       "      <td>0.167956</td>\n",
       "      <td>0.034807</td>\n",
       "      <td>0.215930</td>\n",
       "      <td>0.035543</td>\n",
       "      <td>0.133610</td>\n",
       "      <td>0.110589</td>\n",
       "      <td>0.092357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.078210</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>0.052569</td>\n",
       "      <td>0.046132</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.089690</td>\n",
       "      <td>0.092372</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.068769</td>\n",
       "      <td>0.172192</td>\n",
       "      <td>0.218539</td>\n",
       "      <td>0.092908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.025754</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.185086</td>\n",
       "      <td>0.206419</td>\n",
       "      <td>0.160869</td>\n",
       "      <td>0.075726</td>\n",
       "      <td>0.054200</td>\n",
       "      <td>0.056890</td>\n",
       "      <td>0.061695</td>\n",
       "      <td>0.142226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.070615</td>\n",
       "      <td>0.014123</td>\n",
       "      <td>0.484738</td>\n",
       "      <td>0.041913</td>\n",
       "      <td>0.088383</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.212756</td>\n",
       "      <td>0.022323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.012074</td>\n",
       "      <td>0.206411</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>0.045134</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.006037</td>\n",
       "      <td>0.635906</td>\n",
       "      <td>0.009918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.042454</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.043935</td>\n",
       "      <td>0.149134</td>\n",
       "      <td>0.240094</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>0.004659</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.262344</td>\n",
       "      <td>0.176827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.063275</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.014553</td>\n",
       "      <td>0.107062</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.038724</td>\n",
       "      <td>0.034548</td>\n",
       "      <td>0.069603</td>\n",
       "      <td>0.320931</td>\n",
       "      <td>0.323589</td>\n",
       "      <td>0.016958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           NUM      CONJ       ADV       ADJ       PRT      VERB         .  \\\n",
       "NUM   0.184220  0.014281  0.003570  0.035345  0.026062  0.020707  0.119243   \n",
       "CONJ  0.040615  0.000549  0.057080  0.113611  0.004391  0.150384  0.035126   \n",
       "ADV   0.029868  0.006982  0.081458  0.130721  0.014740  0.339022  0.139255   \n",
       "ADJ   0.021748  0.016893  0.005243  0.063301  0.011456  0.011456  0.066019   \n",
       "PRT   0.056751  0.002348  0.009393  0.082975  0.001174  0.401174  0.045010   \n",
       "VERB  0.022836  0.005433  0.083886  0.066390  0.030663  0.167956  0.034807   \n",
       ".     0.078210  0.060079  0.052569  0.046132  0.002789  0.089690  0.092372   \n",
       "X     0.003075  0.010379  0.025754  0.017682  0.185086  0.206419  0.160869   \n",
       "PRON  0.006834  0.005011  0.036902  0.070615  0.014123  0.484738  0.041913   \n",
       "DET   0.022855  0.000431  0.012074  0.206411  0.000287  0.040247  0.017393   \n",
       "NOUN  0.009144  0.042454  0.016895  0.012584  0.043935  0.149134  0.240094   \n",
       "ADP   0.063275  0.001012  0.014553  0.107062  0.001266  0.008479  0.038724   \n",
       "\n",
       "             X      PRON       DET      NOUN       ADP  \n",
       "NUM   0.202428  0.001428  0.003570  0.351660  0.037487  \n",
       "CONJ  0.009330  0.060373  0.123491  0.349067  0.055982  \n",
       "ADV   0.022886  0.012025  0.071373  0.032196  0.119472  \n",
       "ADJ   0.020971  0.000194  0.005243  0.696893  0.080583  \n",
       "PRT   0.012133  0.017613  0.101370  0.250489  0.019569  \n",
       "VERB  0.215930  0.035543  0.133610  0.110589  0.092357  \n",
       ".     0.025641  0.068769  0.172192  0.218539  0.092908  \n",
       "X     0.075726  0.054200  0.056890  0.061695  0.142226  \n",
       "PRON  0.088383  0.006834  0.009567  0.212756  0.022323  \n",
       "DET   0.045134  0.003306  0.006037  0.635906  0.009918  \n",
       "NOUN  0.028825  0.004659  0.013106  0.262344  0.176827  \n",
       "ADP   0.034548  0.069603  0.320931  0.323589  0.016958  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))\n",
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    \n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  39.07226204872131\n",
      "Vanilla Viterbi Algorithm Accuracy:  92.90780141843972\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NUM', 0.03487735026771261),\n",
       " ('CONJ', 0.02268708753579878),\n",
       " ('ADV', 0.03210061013572407),\n",
       " ('ADJ', 0.06412650977462334),\n",
       " ('PRT', 0.03181421989789565),\n",
       " ('VERB', 0.13522599925289502),\n",
       " ('.', 0.11606275681733283),\n",
       " ('X', 0.06478645249657577),\n",
       " ('PRON', 0.02733159008840742),\n",
       " ('DET', 0.0866268210683601),\n",
       " ('NOUN', 0.28596687834640766),\n",
       " ('ADP', 0.09839372431826672)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "       \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken :  35.562872648239136\n",
      "Modified Viterbi_1 Accuracy:  0.950354609929078\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken : \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
